{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: using Linear Programming to solve for 3 latent factors `w`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the last part of this example, \"Permutation invariance in linear programming vs. MultiCCA in R and `pmd`\" requires that `inpt3` be exactly as printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sparsecca import lp_pmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example inputs\n",
    "inpt1 = pd.read_csv(\"../tests/data/multicca1.csv\", sep=\",\", index_col=0).values\n",
    "inpt2 = pd.read_csv(\"../tests/data/multicca2.csv\", sep=\",\", index_col=0).values[:, -5:]\n",
    "inpt3 = np.random.normal(size=inpt2.shape)\n",
    "\n",
    "penalties = [1.5, 1.5, 1.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert inpt1.shape[0] == inpt2.shape[0] == inpt3.shape[0]\n",
    "inpt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-90.17027552,  11.82731312,  -7.86532209,  17.62955376,\n",
       "        -17.56197152],\n",
       "       [ 51.8255256 ,   6.41554333, -14.01087688, -46.99815802,\n",
       "         16.29765355],\n",
       "       [ 74.04185358,  29.92014574, -26.72555091, -42.34996728,\n",
       "         26.97207374],\n",
       "       [-47.72640718, -18.39841178, -21.55303292,  37.29813179,\n",
       "        -27.72045331],\n",
       "       [ -6.14657028,  18.29437855,   4.43004474,  -2.18546732,\n",
       "         12.80321423]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(inpt1.T @ inpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, svd_init = lp_pmd(\n",
    "    datasets=[inpt1, inpt2], # match feature dimension for now\n",
    "    penalties=penalties[:2],\n",
    "    K=3,\n",
    "    standardize=True,\n",
    "    mimic_R=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.83859139],\n",
       "       [-0.83859139,  1.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pearson correlation of weights[0] and weights[1]\n",
    "np.corrcoef(weights[0].flatten(), weights[1].flatten())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation between pmd results and lp results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sparsecca import multicca_pmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### high correlation between pmd and lp when `n=2`\n",
    "\n",
    "Let `n` equal the number of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [inpt1, inpt2]\n",
    "ws_lp, _ = lp_pmd(datasets, penalties[:2])\n",
    "ws_r, _ = multicca_pmd(datasets, penalties[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=-0.9746794344808964, pvalue=0.004818230468198537)\n",
      "SignificanceResult(statistic=0.09999999999999999, pvalue=0.8728885715695383)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(ws_lp[0], ws_r[0]))\n",
    "print(spearmanr(ws_lp[1], ws_r[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is the same as taking the first latent factor when K=3, as per the implementation in Witten 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=-0.9746794344808964, pvalue=0.004818230468198537)\n",
      "SignificanceResult(statistic=0.09999999999999999, pvalue=0.8728885715695383)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(weights[0].T[0], ws_r[0]))\n",
    "print(spearmanr(weights[1].T[0], ws_r[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arbitrarily lower correlation when `n=3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare when `n=3`. Note that this is subject to the same warning as in the bottom of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [inpt1, inpt2, inpt3]\n",
    "ws_lp, _ = lp_pmd(datasets, penalties)\n",
    "ws_r, _ = multicca_pmd(datasets, penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignificanceResult(statistic=-0.8207826816681233, pvalue=0.08858700531354381)\n",
      "SignificanceResult(statistic=-0.09999999999999999, pvalue=0.8728885715695383)\n",
      "SignificanceResult(statistic=-0.8207826816681233, pvalue=0.08858700531354381)\n"
     ]
    }
   ],
   "source": [
    "print(spearmanr(ws_lp[0], ws_r[0]))\n",
    "print(spearmanr(ws_lp[1], ws_r[1]))\n",
    "print(spearmanr(ws_lp[2], ws_r[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization of the objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the objective function, which was maximized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st pair: [[2.36359908e-06]]\n",
      "2nd pair: [[5.40590458e-07]]\n",
      "3rd pair: [[51.33244746]]\n",
      "sum [[51.33245036]]\n"
     ]
    }
   ],
   "source": [
    "print('1st pair:', ws_lp[0].T @ inpt1.T @ inpt2 @ ws_lp[1])\n",
    "print('2nd pair:', ws_lp[1].T @ inpt2.T @ inpt3 @ ws_lp[2])\n",
    "print('3rd pair:', ws_lp[2].T @ inpt3.T @ inpt1 @ ws_lp[0])\n",
    "print('sum', ws_lp[0].T @ inpt1.T @ inpt2 @ ws_lp[1] + ws_lp[1].T @ inpt2.T @ inpt3 @ ws_lp[2] + ws_lp[2].T @ inpt3.T @ inpt1 @ ws_lp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st pair: [[99.11315683]]\n",
      "2nd pair: [[41.60492912]]\n",
      "3rd pair: [[31.5520592]]\n",
      "sum [[172.27014515]]\n"
     ]
    }
   ],
   "source": [
    "print('1st pair:', ws_r[0].T @ inpt1.T @ inpt2 @ ws_r[1])\n",
    "print('2nd pair:', ws_r[1].T @ inpt2.T @ inpt3 @ ws_r[2])\n",
    "print('3rd pair:', ws_r[2].T @ inpt3.T @ inpt1 @ ws_r[0])\n",
    "print('sum', ws_r[0].T @ inpt1.T @ inpt2 @ ws_r[1] + ws_r[1].T @ inpt2.T @ inpt3 @ ws_r[2] + ws_r[2].T @ inpt3.T @ inpt1 @ ws_r[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 norm of the latent factors, constrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135829891374"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(ws_lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(ws_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither linear programming nor manual convergence consistently produces a better optimization of the objective function in this small test case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation invariance in linear programming vs. MultiCCA in R and `pmd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_weights(weights_a, weights_b, perm_b: list[int], dec=5):\n",
    "    \"\"\"Tests whether `weights_a` and `weights_b` are the same given the permutation order of b.\n",
    "\n",
    "    Parameters:\n",
    "        weights_a: output of lp_pmd \n",
    "        weights_b: output of lp_pmd permuted Xn\n",
    "                   -> weights are of type np.ndarray in shape (N, f, K)\n",
    "                    - N: len(Xn) datasets\n",
    "                    - f: amount of features\n",
    "                    - K: amount of MCPs\n",
    "        perm_b:    order of the datasets used to generate a, in b\n",
    "        dec:       decimals to which weights should be rounded to account for numerical tolerance\n",
    "\n",
    "    Returns:\n",
    "        boolean: True if rounded weights are the same, else False\n",
    "    \"\"\"\n",
    "    \n",
    "    weights_a_rounded = np.array(weights_a).round(decimals=dec)\n",
    "    weights_b_rounded = np.array(weights_b).round(decimals=dec)\n",
    "    \n",
    "    weights_b_ordered = []\n",
    "    for o in perm_b:\n",
    "        weights_b_ordered.append(weights_b_rounded[o])\n",
    "        \n",
    "    return all(x==True for x in (weights_a_rounded==weights_b_ordered).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [inpt1, inpt2, inpt3]\n",
    "# original dataset with perm 1, 2, 0\n",
    "datasets_perm = [inpt3, inpt1, inpt2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = 1e-10\n",
    "\n",
    "ws_lp, _ = lp_pmd(datasets, [0.4, 0.0, 0.4])\n",
    "ws_lp = np.array(ws_lp)\n",
    "ws_lp[np.isclose(ws_lp, 0, rtol=threshold)] = 0\n",
    "\n",
    "ws_lp_perm, _ = lp_pmd(datasets_perm, [0.4, 0.0, 0.4])\n",
    "ws_lp_perm = np.array(ws_lp_perm)\n",
    "ws_lp_perm[np.isclose(ws_lp, 0, rtol=threshold)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-6.09416697e-01],\n",
       "        [-7.92850123e-01],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 8.88854528e-08],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[ 8.69830201e-01],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-4.93351244e-01],\n",
       "        [ 0.00000000e+00]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.73418393e-18],\n",
       "        [-1.01421456e-17],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 3.46602125e-11],\n",
       "        [ 0.00000000e+00]],\n",
       "\n",
       "       [[ 8.62126560e-01],\n",
       "        [ 0.00000000e+00],\n",
       "        [ 0.00000000e+00],\n",
       "        [-5.06693026e-01],\n",
       "        [ 0.00000000e+00]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_lp_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(ws_lp, ws_lp_perm, [1,2,0], dec=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the weights are the same with merely the order permuted as is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R (in python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_r, _ = multicca_pmd(datasets, penalties)\n",
    "ws_r_perm, _ = multicca_pmd(datasets_perm, penalties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        ],\n",
       "        [ 0.90824506],\n",
       "        [ 0.29728456],\n",
       "        [-0.29447039],\n",
       "        [ 0.        ]]),\n",
       " array([[ 0.56055407],\n",
       "        [-0.07202121],\n",
       "        [ 0.04359745],\n",
       "        [-0.82382725],\n",
       "        [ 0.        ]]),\n",
       " array([[-0.7682389 ],\n",
       "        [-0.09935492],\n",
       "        [-0.63240619],\n",
       "        [ 0.        ],\n",
       "        [-0.        ]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.76824118],\n",
       "        [-0.09935549],\n",
       "        [-0.63240334],\n",
       "        [ 0.        ],\n",
       "        [-0.        ]]),\n",
       " array([[ 0.        ],\n",
       "        [ 0.90824509],\n",
       "        [ 0.29727909],\n",
       "        [-0.29447581],\n",
       "        [ 0.        ]]),\n",
       " array([[ 0.5605532 ],\n",
       "        [-0.0720213 ],\n",
       "        [ 0.04359766],\n",
       "        [-0.82382782],\n",
       "        [ 0.        ]])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_r_perm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with decimal tolerance 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO sparsity: 0.4\n",
      "LP sparsity: 0.6\n",
      "IO sparsity: 0.19999999999999996\n",
      "LP sparsity: 0.8\n",
      "IO sparsity: 0.4\n",
      "LP sparsity: 0.6\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ws_r)):\n",
    "    print(\"IO penalties:\", 1 - np.count_nonzero(ws_r[i]) / ws_r[i].size)\n",
    "    print(\"LP penalties:\", 1 - np.count_nonzero(ws_lp[i]) / ws_lp[i].size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(np.array(ws_r), np.array(ws_r_perm), [1,2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test with decimal tolerance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(np.array(ws_r), np.array(ws_r_perm), [1,2,0], dec=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the equivalent negative solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_weights(np.array(ws_r), -np.array(ws_r_perm), [1,2,0], dec=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: linear programming will always solve for the same objective function regardless of the order of the inputs, but the custom PMD implementation in `multicca_pmd` will not. Depending on the dataset, the solution may converge similarly regardless of order (with only a difference in sign), or the solution may converge to a completely different local minima given a different order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
