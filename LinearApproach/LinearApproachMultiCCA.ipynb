{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce8a32ac",
   "metadata": {},
   "source": [
    "# Linear Programming to solve for best weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "mcca2 = pd.read_csv(\"../tests/data/multicca2.csv\", sep=\",\")\n",
    "mcca1 = pd.read_csv(\"../tests/data/multicca1.csv\", sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "3627fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyomo.environ as pyo\n",
    "from scipy.linalg import svd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8e988a8",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "8ad3d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only values from datsets\n",
    "datasets = [mcca1.iloc[:,1:7].values, mcca2.iloc[:,1:6].values]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "912802db",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "8a972474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter \n",
    "standardize = True\n",
    "mimic_R = True\n",
    "# penalties same length as datasets\n",
    "penalties = [1, 1]\n",
    "K = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "b4009789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(mtx, center=True, scale=True):\n",
    "    \"\"\"\n",
    "    Reimplement scale function from R\n",
    "    \"\"\"\n",
    "    if not center:\n",
    "        raise NotImplementedError('Scaling without centering not implemented')\n",
    "\n",
    "    centered = mtx - np.mean(mtx, axis=0)\n",
    "    if not scale:\n",
    "        return centered\n",
    "\n",
    "    # to replicate the R implementation of scale, we apply Bessel's\n",
    "    # correction when calculating the standard deviation in numpy\n",
    "    scaled = centered / centered.std(axis=0, ddof=1)\n",
    "    return scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "bc9cac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "datasets = datasets.copy()\n",
    "# 2 features needed\n",
    "for data in datasets:\n",
    "    if len(data[0]) < 2:\n",
    "        raise Exception('Need at least 2 features in each dataset')\n",
    "\n",
    "    # standardize if set TRUE\n",
    "if standardize:\n",
    "    for idx in range(len(datasets)):\n",
    "        if mimic_R:\n",
    "            datasets[idx] = scale(datasets[idx], center=True, scale=True)\n",
    "        else:\n",
    "            datasets[idx] = scale(datasets[idx], center=True, scale=False)\n",
    "        datasets[idx] = datasets[idx].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "34ece37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets_as_tuples = [tuple(map(tuple,data)) for data in datasets] #(hashable)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2440e1e9",
   "metadata": {},
   "source": [
    "## Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyo.ConcreteModel()\n",
    "\n",
    "model.Idx = pyo.Set(initialize=range(len(datasets)))\n",
    "model.samples = pyo.Set(initialize=range(len(datasets[0])))\n",
    "model.PC = pyo.Set(initialize=range(len(datasets[0][0])))\n",
    "model.K = pyo.Set(initialize=range(K))\n",
    "model.X = pyo.Set(initialize=datasets) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3c55d3ec",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8032d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: ci i in [1:K]\n",
    "model.c = pyo.Param(model.Idx, initialize=penalties)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6e7ed58",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "1446fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.w_i_k_f = pyo.Var(model.Idx,model.K, model.PC, bounds=(0, 1), initialize=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7175c3",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351e4a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjRule(model):\n",
    "    \"\"\"Objective Function (4.3 in witten 2009)\"\"\"\n",
    "    features = len(model.PC.data())\n",
    "    samples = len(model.samples.data())\n",
    "    #TODO: array from  w_i_k (for all pcs)\n",
    "    return sum(\n",
    "                sum((np.asarray([[model.w_i_k_f[idx, k, f] for f in model.PC.data()] for k in model.K.data()])\n",
    "               @ np.asarray(xi).reshape(samples,features).T \n",
    "               @ np.asarray(xj).reshape(samples,features)\n",
    "               @ np.asarray([[model.w_i_k_f[jdx, k, f] for f in model.PC.data()] for k in model.K.data()]).T)[r,c] for r in model.K.data() for c in model.K.data())\n",
    "               for idx, xi in enumerate(model.X) for jdx, xj in enumerate(model.X) if idx<jdx )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "a6264823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective\n",
    "model.Obj = pyo.Objective(rule=ObjRule, sense=pyo.maximize)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "262ae1de",
   "metadata": {},
   "source": [
    "## Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "71c0fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constraints: lasso \n",
    "model.constraint_lasso = pyo.ConstraintList()\n",
    "for i in model.Idx:\n",
    "    model.constraint_lasso.add(sum(model.w_i_k_f[i,k,f] for k in model.K.data() for f in model.PC.data())<= model.c[i])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.constraint_norm2 = pyo.ConstraintList()\n",
    "#model.constraint_norm2.add(model.X, rule=norm2)\n",
    "for i in model.Idx:\n",
    "    model.constraint_norm2.add(sum(model.w_i_k_f[i,k,f] * model.w_i_k_f[i,k,f] for k in model.K.data() for f in model.PC.data()) <= 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f33c940",
   "metadata": {},
   "source": [
    "## Solve with ipopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b1cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonLinearOpt =pyo.SolverFactory('ipopt')\n",
    "instance_non_linear = model.create_instance()\n",
    "res = nonLinearOpt.solve(instance_non_linear)\n",
    "model.solutions.load_from(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657e27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_non_linear.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33d4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = defaultdict(list)\n",
    "for i in model.Idx:\n",
    "    for k in model.K.data():\n",
    "        for f in model.PC.data():\n",
    "            w[i,k].append(instance_non_linear.w_i_k_f[i,k,f].value) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c20c0af1",
   "metadata": {},
   "source": [
    "## For K>1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "631af993",
   "metadata": {},
   "source": [
    "functions can also be found in _multicca_pmd-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(mtx, center=True, scale=True):\n",
    "    \"\"\"\n",
    "    Reimplement scale function from R\n",
    "    \"\"\"\n",
    "    if not center:\n",
    "        raise NotImplementedError('Scaling without centering not implemented')\n",
    "\n",
    "    centered = mtx - np.mean(mtx, axis=0)\n",
    "    if not scale:\n",
    "        return centered\n",
    "\n",
    "    # to replicate the R implementation of scale, we apply Bessel's\n",
    "    # correction when calculating the standard deviation in numpy\n",
    "    scaled = centered / centered.std(axis=0, ddof=1)\n",
    "    return scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_datasets(datasets:list):\n",
    "    # preprocess data\n",
    "    datasets = datasets.copy()\n",
    "    # 2 features needed\n",
    "    for data in datasets:\n",
    "        if len(data[0]) < 2:\n",
    "            raise Exception('Need at least 2 features in each dataset')\n",
    "\n",
    "        # standardize if set TRUE\n",
    "    if standardize:\n",
    "        for idx in range(len(datasets)):\n",
    "            if mimic_R:\n",
    "                datasets[idx] = scale(datasets[idx], center=True, scale=True)\n",
    "            else:\n",
    "                datasets[idx] = scale(datasets[idx], center=True, scale=False)\n",
    "\n",
    "            datasets[idx] = datasets[idx].tolist()\n",
    "            \n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82881b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjRule(model):\n",
    "    \"\"\"Objective Function (4.3 in witten 2009)\"\"\"\n",
    "    features = len(model.PC.data())\n",
    "    samples = len(model.samples.data())\n",
    "    return sum(\n",
    "                (np.asarray([model.w_i_f[idx, f] for f in model.PC.data()])[np.newaxis]\n",
    "               @ np.asarray(xi).reshape(samples,features).T \n",
    "               @ np.asarray(xj).reshape(samples,features)\n",
    "               @ np.asarray([model.w_i_f[jdx, f] for f in model.PC.data()])[np.newaxis].T)[0,0] \n",
    "               for idx, xi in enumerate(model.X) for jdx, xj in enumerate(model.X) if idx<jdx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a33c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_linear_approach(datasets, penalties):\n",
    "    model = pyo.ConcreteModel()\n",
    "\n",
    "    # sets\n",
    "    model.Idx = pyo.Set(initialize=range(len(datasets)))\n",
    "    model.samples = pyo.Set(initialize=range(len(datasets[0])))\n",
    "    model.PC = pyo.Set(initialize=range(len(datasets[0][0])))\n",
    "    model.X = pyo.Set(initialize=datasets)\n",
    "    \n",
    "    # parameters\n",
    "    model.c = pyo.Param(model.Idx, initialize=penalties)\n",
    "\n",
    "    # var\n",
    "    model.w_i_f = pyo.Var(model.Idx, model.PC, bounds=(0, 1), initialize=0.5)\n",
    "\n",
    "    # obj\n",
    "    model.Obj = pyo.Objective(rule=ObjRule, sense=pyo.maximize)\n",
    "    \n",
    "    # constraints: lasso \n",
    "    model.constraint_lasso = pyo.ConstraintList()\n",
    "    for i in model.Idx:\n",
    "        model.constraint_lasso.add(sum(model.w_i_f[i,f] for f in model.PC.data())<= model.c[i])\n",
    "        \n",
    "    # constraints: (2-norm)^2 ||wi||22 <=1\n",
    "    model.constraint_norm2 = pyo.ConstraintList()\n",
    "    for i in model.Idx:\n",
    "        model.constraint_norm2.add(sum(model.w_i_f[i,f] * model.w_i_f[i,f] for f in model.PC.data()) <= 1)\n",
    "        \n",
    "    nonLinearOpt = pyo.SolverFactory('ipopt')\n",
    "    instance_non_linear = model.create_instance()\n",
    "    res = nonLinearOpt.solve(instance_non_linear)\n",
    "    model.solutions.load_from(res)\n",
    "    \n",
    "    instance_non_linear.display()\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    w = defaultdict(list)\n",
    "    for i in model.Idx:\n",
    "        for f in model.PC.data():\n",
    "            w[i].append(instance_non_linear.w_i_f[i,f].value) \n",
    "            \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d1683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_process_K(datasets:list, penalties:list, K:int):\n",
    "    \"\"\" calculates K weights [1xN]\n",
    "        input:  datasets: N matrices [samples x features]\n",
    "                penalties: list of length N (same as datasets)\n",
    "                K: Amount of MCPs\n",
    "        returns: wei\"\"\"\n",
    "    sample_size = len(datasets[0])\n",
    "    feature_amount = len(datasets[0][0])\n",
    "    \n",
    "    datasets_next = preprocess_datasets(datasets)\n",
    "    weights = []\n",
    "    \n",
    "    k = 0\n",
    "    while k < K:\n",
    "        w = do_linear_approach(datasets_next)\n",
    "        datasets_current = datasets_next\n",
    "    \n",
    "        w_samples = {}\n",
    "        for w_n in w:\n",
    "            w_sample = np.repeat(w[w_n],sample_size, axis=0).reshape(sample_size,feature_amount)\n",
    "            w_samples[w_n] = w_sample\n",
    "\n",
    "        datasets_next = []\n",
    "        count=0\n",
    "        for X_i in datasets_current:\n",
    "            X_i_next = X_i - w_samples[count]\n",
    "            datasets_next.append(X_i_next.tolist())\n",
    "            count+=1\n",
    "            \n",
    "        weights.append(w)      \n",
    "            \n",
    "        k += 1\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92956382",
   "metadata": {},
   "source": [
    "### find 3 solutions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = iterative_process_K(datasets, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
